%YAML:1.0 # need to specify the file type at the top!

verbosity: "INFO" # ALL, DEBUG, INFO, WARNING, ERROR, SILENT

use_fej: true # if first-estimate Jacobians should be used (enable for good consistency)
use_imuavg: true # if using discrete integration, if we should average sequential IMU measurements to "smooth" it
use_rk4int: true # if rk4 integration should be used (overrides imu averaging)

use_stereo: true # if we have more than 1 camera, if we should try to track stereo constraints between pairs
max_cameras: 2 # how many cameras we have 1 = mono, 2 = stereo, >2 = binocular (all mono tracking)

calib_cam_extrinsics: true # if the transform between camera and IMU should be optimized R_ItoC, p_CinI
calib_cam_intrinsics: false # if camera intrinsics should be optimized (focal, center, distortion)
calib_cam_timeoffset: true # if timeoffset between camera and IMU should be optimized

max_clones: 7 # how many clones in the sliding window
max_slam: 45 # number of features in our state vector
max_slam_in_update: 25 # update can be split into sequential updates of batches, how many in a batch
max_msckf_in_update: 35 # how many MSCKF features to use in the update
dt_slam_delay: 1 # delay before initializing (helps with stability from bad initialization...)

gravity_mag: 9.80665 # magnitude of gravity in this location

feat_rep_msckf: "GLOBAL_3D"
feat_rep_slam: "ANCHORED_MSCKF_INVERSE_DEPTH"
feat_rep_aruco: "ANCHORED_MSCKF_INVERSE_DEPTH"

# zero velocity update parameters we can use
# we support either IMU-based or disparity detection.
try_zupt: false
zupt_chi2_multipler: 0 # set to 0 for only disp-based
zupt_max_velocity: 0.1
zupt_noise_multiplier: 10
zupt_max_disparity: 0.5 # set to 0 for only imu-based
zupt_only_at_beginning: false

# ==================================================================
# ==================================================================

init_window_time: 2.0 # how many seconds to collect initialization information
init_imu_thresh: 0.5 # threshold for variance of the accelerometer to detect a "jerk" in motion
init_max_disparity: 10.0 # max disparity to consider the platform stationary (dependent on resolution)
init_max_features: 50 # how many features to track during initialization (saves on computation)

init_dyn_use: false # if dynamic initialization should be used
init_dyn_mle_opt_calib: false # if we should optimize calibration during intialization (not recommended)
init_dyn_mle_max_iter: 50 # how many iterations the MLE refinement should use (zero to skip the MLE)
init_dyn_mle_max_time: 0.05 # how many seconds the MLE should be completed in
init_dyn_mle_max_threads: 6 # how many threads the MLE should use
init_dyn_num_pose: 6 # number of poses to use within our window time (evenly spaced)
init_dyn_min_deg: 10.0 # orientation change needed to try to init

init_dyn_inflation_ori: 10 # what to inflate the recovered q_GtoI covariance by
init_dyn_inflation_vel: 100 # what to inflate the recovered v_IinG covariance by
init_dyn_inflation_bg: 10 # what to inflate the recovered bias_g covariance by
init_dyn_inflation_ba: 100 # what to inflate the recovered bias_a covariance by
init_dyn_min_rec_cond: 1e-12 # reciprocal condition number thresh for info inversion

init_dyn_bias_g: [ -3.3131164472457223e-03, -9.6123392515557165e-03, 4.4479042059295398e-03] # initial gyroscope bias guess
init_dyn_bias_a: [ -3.9199198422740222e-04, -5.8155878880743986e-02, 9.2584887834805105e-02] # initial accelerometer bias guess

# ==================================================================
# ==================================================================

record_timing_information: false # if we want to record timing information of the method
record_timing_filepath: "/tmp/traj_timing.txt" # https://docs.openvins.com/eval-timing.html#eval-ov-timing-flame

# if we want to save the simulation state and its diagional covariance
# use this with rosrun ov_eval error_simulation
save_total_state: false
filepath_est: "/tmp/ov_estimate.txt"
filepath_std: "/tmp/ov_estimate_std.txt"
filepath_gt: "/tmp/ov_groundtruth.txt"

# ==================================================================
# ==================================================================

# our front-end feature tracking parameters
# we have a KLT and descriptor based (KLT is better implemented...)
use_klt: true # if true we will use KLT, otherwise use a ORB descriptor + robust matching
num_pts: 200 # number of points (per camera) we will extract and try to track
fast_threshold: 30 # threshold for fast extraction (warning: lower threshs can be expensive)
grid_x: 6 # extraction sub-grid count for horizontal direction (uniform tracking)
grid_y: 6 # extraction sub-grid count for vertical direction (uniform tracking)
min_px_dist: 25 # distance between features (features near each other provide less information)
knn_ratio: 0.90 # descriptor knn threshold for the top two descriptor matches
track_frequency: 21.0 # frequency we will perform feature tracking at (in frames per second / hertz)
downsample_cameras: false # will downsample image in half if true
num_opencv_threads: 4 # -1: auto, 0-1: serial, >1: number of threads
histogram_method: "NONE" # NONE, HISTOGRAM, CLAHE

# aruco tag tracker for the system
# DICT_6X6_1000 from https://chev.me/arucogen/
use_aruco: false
num_aruco: 1024
downsize_aruco: true

# ==================================================================
# ==================================================================

# camera noises and chi-squared threshold multipliers
up_msckf_sigma_px: 1
up_msckf_chi2_multipler: 1
up_slam_sigma_px: 1
up_slam_chi2_multipler: 1
up_aruco_sigma_px: 1
up_aruco_chi2_multipler: 1

# masks for our images
use_mask: false
# mask0: "rect.png" #relative to current file frontMask_100.png
mask0: "rect.png" #relative to current file
mask1: "rect.png" #relative to current file


# imu and camera spacial-temporal
# imu config should also have the correct noise values
use_accle_gyro: false
relative_config_imu: "icm40608_imu_chain.yaml"
#relative_config_imucam: "ov9782_imucam_chain_camera1.yaml"
#relative_config_imucam: "ov9782_imucam_chain_camera2.yaml"
relative_config_imucam: "ov9782_imucam_chain_camera3.yaml"

bag_start: 1
bag_durr: -1

# ==================================================================
# fusion params
# ==================================================================


rtk_topic: /rtk_fix
#rtk_topic: /fix

#noise param for fusion
#position noise, 1e-4 for RTK status=4, 1e-2 for RTK status=2
#when status = 2, [0.17, 0.17, 0.68], status = 4, [0.02, 0.02,0.09]
sigma_p: [0.02, 0.02,0.09]
#velocity noise
sigma_v: [0.02, 0.02,0.09]
#roll and pitch noise
sigma_rp: [0.1, 0.1]
#yaw noise
sigma_yaw: 1

# fusion type: 0-fuse all, 1-fuse RTK only, 2-fuse VIO only. This is for debug
fusion_type: 0

# sensor_frequency
rtk_frequency: 10
# vio pose frequency
camera_frequency: 10

# timeshift transform rtk measurement at time t_rtk to imu0 time system t_imu: [s] (t_imu = t_rtk + shift)
timeshift_rtk_imu: 0.0

# from rtk to imu, to do: delete in future
p_imu_rtk: [0.1183, 0.2578, 0.3207]   # [0.1059, 0.2789, 0.2900] [0.1051, 0.2519, 0.2885]

# cam to robot: Trc, original calibration result
# T_robot_cam: 
#   - [0.068406, -0.574128, 0.815903, 0.434392]
#   - [-0.995994, -0.086512, 0.022628, 0.020235]
#   - [0.057594, -0.814182, -0.577746, 0.2662]
#   - [0, 0, 0, 1]
#T_robot_cam:
#  - [ 0.068406, -0.574128, 0.815903, 0.404392 ]
#  - [ -0.995994, -0.086512, 0.022628, -0.000235 ]
#  - [ 0.057594, -0.814182, -0.577746, 0.2662 ]
#  - [ 0, 0, 0, 1 ]

## first calibration
T_robot_cam:
  - [0.002146, -0.583438,  0.812155, 0.456535]
  - [-0.996440, -0.069698, -0.047437, -0.001914]
  - [0.084282, -0.809161, -0.581511, 0.2662]
  - [0, 0, 0, 1]

## second calibration 
# T_robot_cam:
#   - [0.115569, -0.573799,  0.810801, 0.457736 ]
#   - [-0.991516, -0.115539,  0.059561, 0.033986]
#   - [0.059503, -0.810806, -0.582283, 0.0]
#   - [0, 0, 0, 1]

## third calibration
# T_robot_cam:
#   - [0.014609, -0.607023,  0.794550, 0.435914 ]
#   - [-0.998742, -0.046980, -0.017528, 0.036017]
#   - [0.047968, -0.793295, -0.606945, 0.0]
#   - [0, 0, 0, 1]


# rtk to robot
p_robot_rtk: [0.029, 0.121, 0.238] # [0.015, 0.121, 0.238]

# At least distance for calculation of extrinsic transformation from imu world to enu
initial_distance: 0.5

# image display with the slam feature
display_image: true

# state transfer reflection rate
state_transfer_rate: 1.5

# image time delay
image_time_delay: 0.005

# devergency threshold
divergency_mean: 0.2
divergency_std: 0.1

# data record
record_rosbag: false
record_rosbag_path: "/home/yunye/Documents/EN2301/20231017_双目定位适配/02VL_办公室数据"
rosbag_name: "1017_2_record"

# trajectory display using Robot, must be false if used independent imu propagation
display_robot_flag: false

# output pose, fusion pose: false, imu pose: true
output_imu_pose_flag: false

camrostopic: /camera/image_raw
cam0rostopic: /camera/image_left_raw
cam1rostopic: /camera/image_right_raw
imu0rostopic: /camera/imu


